<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>分库分表后，如何设计深度翻页？ | 繁华流年间</title><meta name="author" content="周五打工人"><meta name="copyright" content="周五打工人"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="遇到mysql 深度翻页这个问题，该如何才能回答得很漂亮，才能 让面试官刮目相看、口水直流。 本文目录- 单表场景，limit深度分页存在的严重性能问题 -问题: 为什么 mysql 深度分页会很慢？- limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort  - 单表场景 limit 深度分页 的优化方法 -1）子查询分页方式-2）join 分页方式- 索引覆盖（Cover">
<meta property="og:type" content="article">
<meta property="og:title" content="分库分表后，如何设计深度翻页？">
<meta property="og:url" content="http://flowtime.asia/2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/index.html">
<meta property="og:site_name" content="繁华流年间">
<meta property="og:description" content="遇到mysql 深度翻页这个问题，该如何才能回答得很漂亮，才能 让面试官刮目相看、口水直流。 本文目录- 单表场景，limit深度分页存在的严重性能问题 -问题: 为什么 mysql 深度分页会很慢？- limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort  - 单表场景 limit 深度分页 的优化方法 -1）子查询分页方式-2）join 分页方式- 索引覆盖（Cover">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://flowtime.asia/img/haibian.png">
<meta property="article:published_time" content="2024-08-25T13:30:46.000Z">
<meta property="article:modified_time" content="2024-08-28T15:07:57.932Z">
<meta property="article:author" content="周五打工人">
<meta property="article:tag" content="深度分页">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://flowtime.asia/img/haibian.png"><link rel="shortcut icon" href="/img/index.jpg"><link rel="canonical" href="http://flowtime.asia/2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-3578075519463317',
  enable_page_level_ads: 'true'
});</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '分库分表后，如何设计深度翻页？',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-28 23:07:57'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/transparent.css"><link rel="stylesheet" href="/css/footer.css"><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/nav.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/haibian.png')"><nav id="nav"><span id="blog-info"><a href="/" title="繁华流年间"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">分库分表后，如何设计深度翻页？</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-08-25T13:30:46.000Z" title="发表于 2024-08-25 21:30:46">2024-08-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="分库分表后，如何设计深度翻页？"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>遇到mysql 深度翻页这个问题，该如何才能回答得很漂亮，才能 让面试官刮目相看、口水直流。</p>
<h2 id="本文目录"><a href="#本文目录" class="headerlink" title="本文目录"></a>本文目录</h2><p><strong><strong>-</strong></strong> <strong>单表场景，limit深度分页存在的严重性能问题</strong></p>
<h5 id="问题-为什么-mysql-深度分页会很慢？"><a href="#问题-为什么-mysql-深度分页会很慢？" class="headerlink" title="-问题: 为什么 mysql 深度分页会很慢？"></a>-问题: 为什么 mysql 深度分页会很慢？</h5><p>- limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort </p>
<p><strong><strong>-</strong></strong> <strong>单表场景 limit 深度分页 的优化方法</strong></p>
<h5 id="1）子查询分页方式"><a href="#1）子查询分页方式" class="headerlink" title="-1）子查询分页方式"></a>-1）子查询分页方式</h5><h5 id="2）join-分页方式"><a href="#2）join-分页方式" class="headerlink" title="-2）join 分页方式"></a>-2）join 分页方式</h5><p><strong><strong>-</strong></strong> <strong>索引覆盖（Cover Index）</strong></p>
<p><strong><strong>-</strong></strong> <strong>单表场景 limit 深度分页  总结</strong></p>
<p><strong><strong>-</strong> 分表场景，limit深度分页存在的严重性能问题</strong></p>
<h5 id="分表场景下-功能和性能的冲突：从0开始的性能瓶颈"><a href="#分表场景下-功能和性能的冲突：从0开始的性能瓶颈" class="headerlink" title="-分表场景下 功能和性能的冲突：从0开始的性能瓶颈"></a>-分表场景下 功能和性能的冲突：从0开始的性能瓶颈</h5><p>- Sharding-JDBC的性能优化措施</p>
<p>- 当然，流式查询的也是有弊端的</p>
<p>- 分表场景+大表场景，limit严重性能问题 如何解决？</p>
<p>- 优化方案1： 禁止跳页查询法</p>
<p>- 优化方法2：二次查询法</p>
<h5 id="二次查询法的一个例子"><a href="#二次查询法的一个例子" class="headerlink" title="-二次查询法的一个例子"></a>-二次查询法的一个例子</h5><p>- 优化方案3：使用 ES+HBASE 海量NOSQL架构方案</p>
<p><strong><strong>-</strong></strong> <strong>说在最后：有问题找老架构取经</strong></p>
<h1 id="单表场景，limit深度分页存在的严重性能问题"><a href="#单表场景，limit深度分页存在的严重性能问题" class="headerlink" title="单表场景，limit深度分页存在的严重性能问题"></a>单表场景，limit深度分页存在的严重性能问题</h1><p>大家的业务接口，常常是分页接口，这样的接口，如果碰到深度分页，都会有慢sql性能问题。</p>
<p>一个小伙伴反馈，他们公司今年3月份时候，线上发生一次大事故。主要后端服务器发生宕机，所有接口超时。宕机半小时后，又自动恢复正常。但是过了2小时，又再次发生宕机。</p>
<p>通过接口日志定位，发现MySQL数据库无法响应服务器。</p>
<p>被刷到7000多页，偏移量（<code>offset</code>）高达20w多。</p>
<p>每当这条SQL执行时，数据库CPU直接打满。</p>
<p>查询时间超过1分钟才有响应。</p>
<p>由于慢查询导致数据库CPU使用率爆满，其他业务的数据库请求无法得到及时响应，接口超时。最后，拖垮主服务器。</p>
<p>所以说，limit深度分页存在的严重性能问题。</p>
<p>MySQL Limit 语法格式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT \* FROM table LIMIT \[offset,\] rows | rows OFFSET offset  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>分页查询时，我们会在 <code>LIMIT</code> 后面传两个参数，一个是偏移量（<code>offset</code>），一个是获取的条数（<code>limit</code>）。</p>
<p>当偏移量很小时，查询速度很快，但是当 <code>offset</code> 很大时，查询速度就会变慢。</p>
<p>假设有一张 300w 条数据的表，对其进行分页查询。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 1, 10  // 32.8ms  </span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 10, 10 // 34.2ms  </span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 100, 10 // 35.4ms  </span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 1000, 10 // 39.6ms  </span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 10000, 10 // 5660ms  </span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 100000, 10 // 61.4 秒  </span><br><span class="line">select \* from user where sex = &#x27;m&#x27; order by age limit 1000000, 10 // 273 秒  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看到，随着偏移量（<code>offset</code>）的增加，查询时间变得越长。</p>
<p>上例中，当偏移的起始位置超过10万时，分页查询的时间超过61秒。</p>
<p>当偏移量超过100万时，查询时间竟然长达273秒。</p>
<p>对于普通的业务而言，超过1秒的查询是绝对不可以忍受的。</p>
<p>从上例中，我们可以总结出：LIMIT分页查询的时间与偏移量值成正比。</p>
<p>当偏移量越大时，查询时间越长。</p>
<p>这种情况，会随着业务的增加，数据的增多，会越发的明显。那么，如何优化这种情况呢？答案是，索引覆盖。</p>
<h3 id="问题-为什么-mysql-深度分页会很慢？-1"><a href="#问题-为什么-mysql-深度分页会很慢？-1" class="headerlink" title="问题: 为什么 mysql 深度分页会很慢？"></a>问题: 为什么 mysql 深度分页会很慢？</h3><p>包括两层，server层和存储引擎层</p>
<p>server层：查询缓存，解析sql语句生成语法树，执行sql。在执行sql中包括预处理器，优化器和执行器。</p>
<ul>
<li><p>预处理器：将查询字段展开（如select * 展开为具体字段）并检查字段是否合法</p>
</li>
<li><p>优化器：指定sql执行计划，如选择合适的索引</p>
</li>
<li><p>执行器：与存储引擎层交互，执行sql语句</p>
</li>
</ul>
<p>存储引擎层 Engine层：如InnoDB和MyISAM。以InnoDB为例，访问B+树数据结构获取记录（聚簇索引，二级索引等的访问都在存储引擎层）</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/1.png"></p>
<h2 id="limit在深度翻页场景下变成了：-全表扫描-文件排序-filesort"><a href="#limit在深度翻页场景下变成了：-全表扫描-文件排序-filesort" class="headerlink" title="limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort"></a>limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort</h2><p>limit 是执行在server 层，而不是innodb层。</p>
<p>也就是说， 在server层 需要获取到 全部的 limit_cout 的结果，在发送给客户端时，才会进行limit操作。</p>
<p>比如如下sql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 1000000, 10 // 273 秒  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>server 层 在执行器调存储引擎api获取到一条数据时，会查看数据是否是第1000000 以后条数据，如果不是，就不会发送到客户端，只进行limit_cout 计数。</p>
<p>server 层 直到10001才会发送到客户端。也就是说，执行 limit m n语句的场景下， Engine层 实际上也会访问前m条数据，然后返回后n条数据。</p>
<p>正是因为 Engine层 limit会扫描每条记录，因此如果我们查询的字段需要回表扫描，每一次查询都会拿着age列的二级索引查到的主键值去回表，limit 1000000 就会回表1000000 次，效率极低。</p>
<p>所以如果我们使用explain查看查询计划：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">explain select \* from user  where sex = &#x27;m&#x27; order by age  limit 1000000, 10  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>其往往不会走age索引，而是全表扫描+filesort，为什么？ 因为优化器认为选择age索引的效率，甚至不如全表扫描+文件排序filesort。</p>
<p>所以，当翻页靠后时，查询会变得很慢，因为随着偏移量的增加，我们需要排序和扫描的非目标行数据也会越来越多，这些数据再扫描后都会被丢弃。</p>
<h1 id="单表场景-limit-深度分页-的优化方法"><a href="#单表场景-limit-深度分页-的优化方法" class="headerlink" title="单表场景 limit 深度分页 的优化方法"></a>单表场景 limit 深度分页 的优化方法</h1><p>对于LIMIT分页查询的性能优化，主要思路是利用  索引覆盖 字段定位数据，然后再取出内容。</p>
<p>不使用索引覆盖，查询耗时情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT \* FROM \`tbl\_works\`  WHERE \`status\`\=1   LIMIT 100000, 10  // 78.3 秒  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1）子查询分页方式-1"><a href="#1）子查询分页方式-1" class="headerlink" title="1）子查询分页方式"></a>1）子查询分页方式</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT \* FROM tbl\_works  </span><br><span class="line">WHERE id &gt;= (SELECT id FROM tbl\_works limit 100000, 1)  </span><br><span class="line">LIMIT 20  // 54ms  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>子查询分页方式，首先通过子查询和索引覆盖定位到起始位置ID，然后再取所需条数的数据。</p>
<p>缺点是，不适用于结果集不以ID连续自增的分页场景。</p>
<p>在复杂分页场景，往往需要通过过滤条件，筛选到符合条件的ID，此时的ID是离散且不连续的。</p>
<p>如果使用上述的方式，并不能筛选出目标数据。</p>
<p>当然，我们也可以对此方法做一些改进，首先利用子查询获取目标分页的 <code>ids</code>，然后再根据 <code>ids</code> 获取内容。 根据直觉将SQL改造如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT \* FROM tbl\_works  </span><br><span class="line">WHERE id IN (SELECT id FROM tbl\_works limit 100000, 10)  </span><br><span class="line">  </span><br><span class="line">// 错误信息：  </span><br><span class="line">// This version of MySQL doesn&#x27;t yet support &#x27;LIMIT &amp; IN/ALL/ANY/SOME subquery&#x27;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然而，并不尽人意。我们得到一个错误提示。 错误信息的含义是，子查询不能有 <code>limit</code>操作。于是，我们对SQL进行了改造，对子查询包了一层：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT t1.\* FROM tbl\_works t1  </span><br><span class="line">WHERE t1.id in (SELECT t2.id from (SELECT id FROM tbl\_works limit 100000, 10) as t2)  // 53.9ms  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>执行成功，且查询效率很高。</p>
<p>但是，这种写法非常繁琐。</p>
<p>我们可以使用下面的 <code>join</code> 分页方式，达到相同的优化效果。实际上，两者的原理是相同的。</p>
<h3 id="2）join-分页方式-1"><a href="#2）join-分页方式-1" class="headerlink" title="2）join 分页方式"></a>2）join 分页方式</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT \* FROM tbl\_works t1   </span><br><span class="line">JOIN (SELECT id from tbl\_works WHERE status=1  limit 100000, 10) t2  </span><br><span class="line">ON t1.id = t2.id  // 53.6 ms  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这条SQL的含义是，通过自连接与<code>join</code>定位到目标 <code>ids</code>，然后再将数据取出。</p>
<p>在定位目标 <code>ids</code>时，由于 <code>SELECT</code>的元素只有主键 <code>ID</code>，且<code>status</code> 存在索引，因此MySQL只需在索引中，就能定位到目标 <code>ids</code>，不用在数据文件上进行查找。</p>
<p>因而，查询效率非常高。</p>
<h1 id="基础知识：什么是-索引覆盖（Cover-Index）"><a href="#基础知识：什么是-索引覆盖（Cover-Index）" class="headerlink" title="基础知识：什么是  索引覆盖（Cover Index）"></a>基础知识：什么是  索引覆盖（Cover Index）</h1><blockquote>
<p>如果索引包含所有满足查询需要的数据的索引，成为索引覆盖(Covering Index)，也就是平时所说的不需要回表操作。</p>
</blockquote>
<p><strong>索引覆盖（Index Covering）</strong>是指<strong>一个查询可以完全通过索引来执行，而无需访问实际的数据行</strong>。</p>
<p>在数据库中，通常查询语句包含了一系列的条件，这些条件用于筛选出符合特定条件的数据行。</p>
<p>如果这些条件能够通过索引直接定位到符合条件的数据行，而无需访问实际的数据页，那么就称为索引覆盖。</p>
<p>比如我们有这样一条SQL语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select name,age,level from user where name = &quot;AAA&quot; and age  17  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>那么，我们添加一个联合索引，覆盖所有的查询内容, 联合索引如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">key \`idx\_nal\` (\`name\`,\`age\`,\`level\`) using btree  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>有了这个联合索引，我们在搜索的时候，只需要通过索引就能够拿到我们需要的全部数据了。</p>
<p>简单的说，索引覆盖覆盖所有需要查询的字段（即，大于或等于所查询的字段）。MySQL可以通过索引获取查询数据， 这样就避免了回表，不需要读取数据行。</p>
<p>索引覆盖注意事项：</p>
<p>1.如果一个索引<strong>包含了需要查询的所有字段</strong>，那么这个索引就是覆盖索引。</p>
<p>2.MySQL <strong>只能使用B+Tree</strong>索引做覆盖索引，因为只有B+树能存储索引列值</p>
<p>索引覆盖的好处：</p>
<ol>
<li><p>索引大小远小于数据行大小。因而，如果只读取索引，则能极大减少对数据访问量。</p>
</li>
<li><p>索引按顺序储存。对于IO密集型的范围查询会比随机从磁盘读取每一行数据的IO要少。</p>
</li>
<li><p>避免对主键索引的二次查询。二级索引的叶子节点包含了主键的值，如果二级索引包含所要查询的值，则能避免二次查询主键索引（聚簇索引，聚簇索引既存储了索引，也储存了值）。</p>
</li>
</ol>
<h1 id="单表场景-limit-深度分页-总结"><a href="#单表场景-limit-深度分页-总结" class="headerlink" title="单表场景 limit 深度分页 总结"></a>单表场景 limit 深度分页 总结</h1><p>通过利用索引覆盖，能极大的优化了Limit分页查询的效率。</p>
<p>在真正的实践中，除了使用索引覆盖，优化查询速度外，我们还可以使用 Redis 缓存，将热点数据进行缓存储存。</p>
<p>背景描述的事故，我们考虑了时间成本和业务复杂度后，最后采取的是限制分页和增加缓存。</p>
<p>所谓的限制分页，即在不影响阅读体验的前提下，只允许用户可以查看前几千条的数据。</p>
<p>经测验，偏移量较小时的查询效率较令人满意，查询效率接近使用索引覆盖查询的速度。</p>
<h1 id="分表场景，limit深度分页存在的严重性能问题"><a href="#分表场景，limit深度分页存在的严重性能问题" class="headerlink" title="分表场景，limit深度分页存在的严重性能问题"></a>分表场景，limit深度分页存在的严重性能问题</h1><p>大家知道 ，当一个表（比如订单表） 达到500万条或2GB时，需要考虑水平分表。</p>
<p>比如大型的电商系统中的订单服务，业务量很少时，单库单表基本扛得住，但是随着时间推移，数据量越来越多，订单服务在读写的性能上逐渐变差。</p>
<p>这里也介绍是，是Sharding-JDBC 的 limit深度分页 执行逻辑和性能问题。</p>
<p>Sharding-JDBC从多个分表获取分页数据，与单表分页的执行逻辑，本质是不同的。</p>
<p>分表分页场景下的 分页逻辑， 并不是： 简单的去 每个分表取到同样的数量的数据， 简单归并+挑选 。</p>
<p>分表分页场景下的 分页逻辑，要从 0开始去每一个分表 获取到 limit 全部的数据， 而不是从offset 开始。</p>
<p>如果是深度分页， 比如说：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select \* from user  where sex = &#x27;m&#x27; order by age  limit 1000000, 10 // 273 秒  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>那么要去每一个 分表 获取到 limit 全部的1000000 + 10 条 数据 ， 会导致每一个分表都走 全表扫描+ 文件排序 filesort ， 每一个分表的性能都很低。</p>
<p>当然，在这里带大家首先要解决的问题是： 为什么 表分页场景下的 分页逻辑，要从 0开始去每一个分表 获取到 limit 全部的数据， 而不是从offset 开始。</p>
<p>假设每10条数据为一页，取第2页数据。 </p>
<p>在分片环境下获取LIMIT 10, 10，归并之后再根据排序条件取出前10条数据是不正确的。</p>
<p>举例说明，若SQL为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT score FROM t\_score ORDER BY score DESC LIMIT 1, 2;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>下图展示了不进行SQL的改写的分页执行结果：</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/2.png"></p>
<p>通过图中所示，想要取得两个表中共同的按照分数排序的第2条和第3条数据，理论上，应该是95和90。</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/3.png"></p>
<p>实际上呢？</p>
<p>由于执行的SQL只能从每个表中获取第2条和第3条数据，即:</p>
<ul>
<li><p>从t_score_0表中获取的是90和80；</p>
</li>
<li><p>从t_score_0表中获取的是85和75。</p>
</li>
</ul>
<p>因此进行结果归并时，只能从获取的90，80，85和75之中进行归并，那么，无论怎么实现，结果归并之后，都不可能获得正确的结果。</p>
<p>正确的做法:</p>
<p>是将分页条件改写为LIMIT 0, 3，取出所有前两页数据，再结合排序条件计算出正确的数据。</p>
<p>下图展示了进行SQL改写之后的分页执行结果。</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/4.png"></p>
<p>回到问题： 为什么 表分页场景下的 分页逻辑，要从 0开始去每一个分表 获取到 limit 全部的数据， 而不是从offset 开始。</p>
<p>答案是： 为了合并之后的结果不出错，每一个分表的查询是必须0开始， 归并之后的结果才不会错。</p>
<h3 id="分表场景下-功能和性能的冲突：从0开始的性能瓶颈-1"><a href="#分表场景下-功能和性能的冲突：从0开始的性能瓶颈-1" class="headerlink" title="分表场景下 功能和性能的冲突：从0开始的性能瓶颈"></a>分表场景下 功能和性能的冲突：从0开始的性能瓶颈</h3><p>注意，这里有个大问题：</p>
<p>为了结果不出错，归并之前的查询，是0开始， 结果才可能是对的。</p>
<p>所以，询偏移量过大的分页会导致数据库获取数据性能低下，<br><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/5.png"></p>
<p>如果不是分库分表，这句SQL会使得MySQL在无法利用索引的情况下跳过1000000条记录后，再获取10条记录，其性能可想而知。</p>
<p>然而， 在分库分表的情况下（假设分为2个库），为了保证数据的正确性，SQL会改写为：</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/6.png"></p>
<p>所以， 分库分表场景， Sharding-JDBC 需要将偏移量前的记录全部取出，归并排序后，挑选最后10条记录。</p>
<p>这会在数据库本身就执行很慢的情况下，进一步加剧性能瓶颈。</p>
<p>因为原SQL仅需要传输10条记录至客户端，而改写之后的SQL则会传输1,000,010 * 2的记录至客户端。</p>
<h2 id="Sharding-JDBC的性能优化措施"><a href="#Sharding-JDBC的性能优化措施" class="headerlink" title="Sharding-JDBC的性能优化措施"></a>Sharding-JDBC的性能优化措施</h2><p>那么，Sharding-JDBC会将全量的记录（如1,000,010 * 2 记录） 都全部加载至内存吗？</p>
<p>不会，这样加载，会占用大量内存而导致内存溢出。</p>
<p>Sharding-JDBC 知道了问题所在，本身也会做优化。</p>
<p>Sharding-JDBC的性能优化措施，主要如下：</p>
<p>（1）<strong>采用流式处理 + 归并排序的方式来避免内存的过量占用。</strong></p>
<p>由于SQL改写不可避免的占用了额外的带宽，但并不会导致内存暴涨。</p>
<p>与直觉不同，大多数人认为Sharding-JDBC会将1,000,010 * 2记录全部加载至内存，进而占用大量内存而导致内存溢出。</p>
<p>但由于每个结果集的记录是有序的，因此Sharding-JDBC每次仅获取各个分片的当前结果集记录，驻留在内存中的记录仅为当前路由到的分片的结果集的当前游标指向而已。</p>
<p><strong>对于本身即有序的待排序对象，归并排序的时间复杂度仅为O(n)，性能损耗很小。</strong></p>
<p>（2）<strong>Sharding-JDBC对仅落至多分片的查询进行进一步优化。</strong></p>
<p>落至单分片查询的请求并不需要改写SQL也可以保证记录的正确性，因此在此种情况下，Sharding-JDBC并未进行SQL改写，从而达到节省带宽的目的。</p>
<p>一般情况下，性能慢，都是第一种情况。</p>
<h2 id="当然，流式查询的也是有弊端的"><a href="#当然，流式查询的也是有弊端的" class="headerlink" title="当然，流式查询的也是有弊端的"></a>当然，流式查询的也是有弊端的</h2><p>采用游标查询的方式的缺点很明显。</p>
<p><em>流式（游标）查询需要注意：当前查询会独占连接！</em></p>
<p><em>必须先读取（或关闭）结果集中的所有行，然后才能对连接发出任何其他查询，否则将引发异常！</em></p>
<p>执行一个流式查询后，数据库访问框架就不负责关闭数据库连接了，需要应用在取完数据后需要自己关闭。</p>
<p>由于MySQL_Server不知道客户端什么时候将数据消费完，而自身的对应表可能会有DML写入操作，<strong>此时MySQL_Server需要建立一个临时空间来存放需要拿走的数据</strong>。</p>
<p>因此对于当你启用useCursorFetch 读取 大表的时候，会看到MySQL上的几个现象：</p>
<ol>
<li><p>IOPS 飙升，因为需要返回的数据需要写入到临时空间中，存在大量的 IO 读取和写入，此流程可能会引起其它业务的写入抖动</p>
</li>
<li><p>磁盘空间飙升，写入临时空间的数据会在读取完成或客户端发起 <strong>ResultSet#close</strong> 操作时由 MySQL_Server 回收</p>
</li>
<li><p>客户端 JDBC 发起sql_query，可能会有长时间等待，这段时间为MySQL_Server准备数据阶段。</p>
<p>但是 普通查询等待时间与游标查询等待时间原理上是不一致的: 前者是在读取网络缓冲区的数据，没有响应到业务层面；后者是 MySQL 在准备临时数据空间，没有响应到 JDBC</p>
</li>
<li><p>数据准备完成后，进行到传输数据阶段，网络响应开始飙升，IOPS 由”写”转变为”读”</p>
</li>
</ol>
<h2 id="分表场景-大表场景，limit严重性能问题-如何解决？"><a href="#分表场景-大表场景，limit严重性能问题-如何解决？" class="headerlink" title="分表场景+大表场景，limit严重性能问题 如何解决？"></a>分表场景+大表场景，limit严重性能问题 如何解决？</h2><p>虽然有流式查询，但是分表场景+大表场景，limit深度翻页还是存在的严重性能问题 ，基本上是分页越大后续的查询越耗资源并且越慢，如何解决呢？</p>
<h2 id="优化方案1：-禁止跳页查询法"><a href="#优化方案1：-禁止跳页查询法" class="headerlink" title="优化方案1： 禁止跳页查询法"></a>优化方案1： 禁止跳页查询法</h2><p>由于LIMIT并不能通过索引查询数据，</p>
<p><strong>因此如果可以保证ID的连续性，通过ID进行分页是比较好的解决方案</strong>：</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/7.png"></p>
<p>或者：通过记录上次查询结果的最后一条记录的ID，进行下一页的查询：</p>
<p><img src="/./2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/8.png"></p>
<p>如果不是id列， 假设排序的列为col，禁止跳页查询法的两个步骤大致如下：</p>
<p>（1）用正常的方法取得第一页数据，并得到第一页记录的 max_col 最大值；</p>
<p>（2）每次翻页，将 order by col offset X limit Y; 改写成 下面的语句</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">order by col  where col&gt;$max\_col  limit Y;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以保证每次只返回一页数据，性能为常量。</p>
<h2 id="优化方法2：二次查询法"><a href="#优化方法2：二次查询法" class="headerlink" title="优化方法2：二次查询法"></a>优化方法2：二次查询法</h2><p>假设排序的列为col，二次查询法的两个步骤大致如下：</p>
<p>（1）分页偏移量平均 offset&#x2F;N(分片数) ，将 order by col offset X limit Y; 改写成</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">order by col  offset X/N limit Y;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（2）多页返回，找到最小值col_min 和 最大 值 col_max；</p>
<p>（3）between二次查询</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">order by col between  col\_min and col\_i\_max;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（4）设置虚拟col_min，找到col_min在各个分表的offset，从而得到col_min在全局的offset；</p>
<p>（5）得到了col_min在全局的offset，自然得到了全局的offset X limit Y；</p>
<h3 id="二次查询法的一个例子-1"><a href="#二次查询法的一个例子-1" class="headerlink" title="二次查询法的一个例子"></a>二次查询法的一个例子</h3><p>例子：分表结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">CREATE TABLE \`student\_time\_0\` (  </span><br><span class="line">  \`id\` int(11) unsigned NOT NULL AUTO\_INCREMENT,  </span><br><span class="line">  \`user\_id\` int(11) NOT NULL,  </span><br><span class="line">  \`name\` varchar(200) COLLATE utf8\_bin DEFAULT NULL,  </span><br><span class="line">  \`age\` tinyint(3) unsigned DEFAULT NULL,  </span><br><span class="line">  \`create\_time\` bigint(20) DEFAULT NULL,  </span><br><span class="line">  PRIMARY KEY (\`id\`)  </span><br><span class="line">) ENGINE\=InnoDB AUTO\_INCREMENT=674 DEFAULT CHARSET\=utf8 COLLATE\=utf8\_bin;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>有这样的三个表</p>
<ul>
<li><p><code>student_time_0</code>,</p>
</li>
<li><p><code>student_time_1</code>,</p>
</li>
<li><p><code>student_time_2</code>,</p>
</li>
</ul>
<p>以 user_id 作为分表键，根据表数量取模作为分表依据</p>
<p>这里先构造点数据，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">insert into student\_time (\`name\`, \`user\_id\`, \`age\`, \`create\_time\`) values (?, ?, ?, ?)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>主要是为了保证 <code>create_time</code> 唯一，比较好说明问题，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">int i = 0;  </span><br><span class="line">try (  </span><br><span class="line">        Connection conn = dataSource.getConnection();  </span><br><span class="line">        PreparedStatement ps = conn.prepareStatement(insertSql)) &#123;  </span><br><span class="line">    do &#123;  </span><br><span class="line">        ps.setString(1, localName + new Random().nextInt(100));  </span><br><span class="line">        ps.setLong(2, 10086L + (new Random().nextInt(100)));  </span><br><span class="line">        ps.setInt(3, 18);  </span><br><span class="line">        ps.setLong(4, new Date().getTime());  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">        int result = ps.executeUpdate();  </span><br><span class="line">        LOGGER.info(&quot;current execute result: &#123;&#125;&quot;, result);  </span><br><span class="line">        Thread.sleep(new Random().nextInt(100));  </span><br><span class="line">        i++;  </span><br><span class="line">    &#125; while (i &lt;= 2000);  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>三个表的数据分别是 673，678，650，各个表数据不一样，</p>
<p>接下来，做一个这样的分页查询</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select \* from student\_time ORDER BY create\_time ASC limit 1000, 5;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>student_time</code> 对于我们使用的 <code>sharding-jdbc</code> 来说当然是逻辑表， sharding-jdbc 会改写为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">select \* from student\_time ORDER BY create\_time ASC limit 0, 1005;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>即使如 sharding-jdbc 对于合并排序的优化做得比较好，也还是需要传输那么大量的数据，并且查询也耗时，那么有没有解决方案呢</p>
<ul>
<li><p>第一个办法禁止跳页，而是只给下一页，那么我们就能把前一次的最大偏移量的 create_time 记录下来，下一页就可以拿着这个偏移量进行查询</p>
</li>
<li><p>第二个办法是二次查询法</p>
</li>
</ul>
<p>这个办法的第一步跟前面那个错误的方法或者说不准确的方法一样，先是将分页偏移量平均 1000&#x2F;3 &#x3D; 333，根据这个 limit 333,5 在三个表里进行查询</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">t0  </span><br><span class="line">334 10158 nick95  18  1641548941767  </span><br><span class="line">335 10098 nick11  18  1641548941879  </span><br><span class="line">336 10167 nick51  18  1641548942089  </span><br><span class="line">337 10167 nick3 18  1641548942119  </span><br><span class="line">338 10170 nick57  18  1641548942169  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">t1  </span><br><span class="line">334 10105 nick98  18  1641548939071   最小  </span><br><span class="line">335 10174 nick94  18  1641548939377  </span><br><span class="line">336 10129 nick85  18  1641548939442  </span><br><span class="line">337 10141 nick84  18  1641548939480  </span><br><span class="line">338 10096 nick74  18  1641548939668  </span><br><span class="line">  </span><br><span class="line">t2  </span><br><span class="line">334 10184 nick11  18  1641548945075  </span><br><span class="line">335 10109 nick93  18  1641548945382  </span><br><span class="line">336 10181 nick41  18  1641548945583  </span><br><span class="line">337 10130 nick80  18  1641548945993  </span><br><span class="line">338 10184 nick19  18  1641548946294  最大  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第一遍的目标是啥，查出来的最小的 create_time 和最大的 create_time 找出来，然后再去三个表里查询，</p>
<p>其实主要是最小值，因为拿着最小值去查，就能知道这个最小值在每个表里处在什么位置，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">order by col between  col\_min and col\_i\_max;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>接下来，将第一遍查出来的最小的 create_time 和最大的 create_time 找出来，然后再去三个表里查询，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">t0  </span><br><span class="line">322 10161 nick81  18  1641548939284  </span><br><span class="line">323 10113 nick16  18  1641548939393  </span><br><span class="line">324 10110 nick56  18  1641548939577  </span><br><span class="line">325 10116 nick69  18  1641548939588  </span><br><span class="line">326 10173 nick51  18  1641548939646  </span><br><span class="line">  </span><br><span class="line">t1  </span><br><span class="line">334 10105 nick98  18  1641548939071  </span><br><span class="line">335 10174 nick94  18  1641548939377  </span><br><span class="line">336 10129 nick85  18  1641548939442  </span><br><span class="line">337 10141 nick84  18  1641548939480  </span><br><span class="line">338 10096 nick74  18  1641548939668  </span><br><span class="line">  </span><br><span class="line">t2  </span><br><span class="line">297 10136 nick28  18  1641548939161  </span><br><span class="line">298 10142 nick68  18  1641548939177  </span><br><span class="line">299 10124 nick41  18  1641548939237  </span><br><span class="line">300 10148 nick87  18  1641548939510  </span><br><span class="line">301 10169 nick23  18  1641548939715  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里只贴了前五条数据，为了方便知道偏移量，每个分表都使用了自增主键，</p>
<p>我们可以看到前一次查询的最小值分别在其他两个表里的位置分别是 322-1 和 297-1，</p>
<p>那么，对于总体来说，这个时间的起始位置，应该是在 <code>322 - 1 + 334-1 + 297 - 1 = 951</code>，</p>
<p>那么，只要对后面的数据最多每个表查 <code>1000 - 951 + 5 = 54</code> 条数据，再进行合并排序就可以获得最终正确的结果。</p>
<p>这个就是的二次查询法。</p>
<p>可见，二次查询法很麻烦， 不如禁止跳页法，或者 es组合方法，直接，有效。</p>
<h2 id="优化方案3：使用-ES-HBASE-海量NOSQL架构方案"><a href="#优化方案3：使用-ES-HBASE-海量NOSQL架构方案" class="headerlink" title="优化方案3：使用 ES+HBASE 海量NOSQL架构方案"></a>优化方案3：使用 ES+HBASE 海量NOSQL架构方案</h2><p>对于海量数据场景，建议使用 ES+HBASE 这样的 海量NOSQL架构方案，具体如下：</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIxMzYwODY3OQ==&mid=2247486355&idx=1&sn=11de825e254f07babb33ec0092023ca3&scene=21#wechat_redirect">100亿级数据存储架构：MYSQL双写 + HABSE +Flink +ES综合大实操</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkxNzIyMTM1NQ==&mid=2247500949&idx=1&sn=7e54bb8171b421ddd980247e7b398efc&scene=21#wechat_redirect">阿里2面：万亿级消息，如何做存储设计？</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkxNzIyMTM1NQ==&mid=2247502366&idx=1&sn=97516e427ed08dee1cdfce7c585f977f&scene=21#wechat_redirect"><strong>字节面试：百亿级存储，怎么设计？只是分库分表？</strong></a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkxNzIyMTM1NQ==&mid=2247502246&idx=1&sn=2383a2bb532e3c41fca3f98bc698fa96&scene=21#wechat_redirect"><strong>100亿级任务调度篇：从0到1, 从入门到 XXLJOB 工业级使用</strong></a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkxNzIyMTM1NQ==&mid=2247502412&idx=1&sn=36ba00af1baa36a759c15f14e365934a&scene=21#wechat_redirect"><strong>高并发搜索ES圣经：从0到1, 从入门到 ElasticSearch 工业级使用</strong></a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkxNzIyMTM1NQ==&mid=2247502644&idx=1&sn=703bc8a56ba7466d13866498d41cc5e9&scene=21#wechat_redirect"><strong>超级底层：10WQPS&#x2F;PB级海量存储HBase&#x2F;RocksDB，底层LSM结构是什么？</strong></a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://flowtime.asia">周五打工人</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://flowtime.asia/2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/">http://flowtime.asia/2024/08/25/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%EF%BC%9F/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://flowtime.asia" target="_blank">繁华流年间</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5/">深度分页</a></div><div class="post_share"><div class="social-share" data-image="/img/haibian.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/08/28/IDEA%E4%B8%ADGit-Reset%E9%80%89%E9%A1%B9%E8%AF%B4%E6%98%8E/" title="IDEA中Git Reset选项说明"><img class="cover" src="/img/hubian.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">IDEA中Git Reset选项说明</div></div></a></div><div class="next-post pull-right"><a href="/2024/08/11/Redis-%E6%9D%80%E7%96%AF%E4%BA%86%E3%80%82%E3%80%82%E3%80%82/" title="Redis 杀疯了。。。"><img class="cover" src="/img/hubian.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Redis 杀疯了。。。</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/nav.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">周五打工人</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">无论你是追求知识的急先锋，还是对生活感悟充满好奇，亦或是渴望找到属于自己情感共鸣的灵魂，本博客都将竭诚欢迎你的加入。共同书写属于自己的精彩篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E6%96%87%E7%9B%AE%E5%BD%95"><span class="toc-number">1.</span> <span class="toc-text">本文目录</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-%E4%B8%BA%E4%BB%80%E4%B9%88-mysql-%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5%E4%BC%9A%E5%BE%88%E6%85%A2%EF%BC%9F"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">-问题: 为什么 mysql 深度分页会很慢？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1%EF%BC%89%E5%AD%90%E6%9F%A5%E8%AF%A2%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F"><span class="toc-number">1.0.0.2.</span> <span class="toc-text">-1）子查询分页方式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%EF%BC%89join-%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F"><span class="toc-number">1.0.0.3.</span> <span class="toc-text">-2）join 分页方式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E8%A1%A8%E5%9C%BA%E6%99%AF%E4%B8%8B-%E5%8A%9F%E8%83%BD%E5%92%8C%E6%80%A7%E8%83%BD%E7%9A%84%E5%86%B2%E7%AA%81%EF%BC%9A%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88"><span class="toc-number">1.0.0.4.</span> <span class="toc-text">-分表场景下 功能和性能的冲突：从0开始的性能瓶颈</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8C%E6%AC%A1%E6%9F%A5%E8%AF%A2%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-number">1.0.0.5.</span> <span class="toc-text">-二次查询法的一个例子</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%95%E8%A1%A8%E5%9C%BA%E6%99%AF%EF%BC%8Climit%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5%E5%AD%98%E5%9C%A8%E7%9A%84%E4%B8%A5%E9%87%8D%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98"><span class="toc-number"></span> <span class="toc-text">单表场景，limit深度分页存在的严重性能问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-%E4%B8%BA%E4%BB%80%E4%B9%88-mysql-%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5%E4%BC%9A%E5%BE%88%E6%85%A2%EF%BC%9F-1"><span class="toc-number">0.1.</span> <span class="toc-text">问题: 为什么 mysql 深度分页会很慢？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#limit%E5%9C%A8%E6%B7%B1%E5%BA%A6%E7%BF%BB%E9%A1%B5%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%8F%98%E6%88%90%E4%BA%86%EF%BC%9A-%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F-%E6%96%87%E4%BB%B6%E6%8E%92%E5%BA%8F-filesort"><span class="toc-number">1.</span> <span class="toc-text">limit在深度翻页场景下变成了： 全表扫描+ 文件排序 filesort</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%95%E8%A1%A8%E5%9C%BA%E6%99%AF-limit-%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5-%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">单表场景 limit 深度分页 的优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89%E5%AD%90%E6%9F%A5%E8%AF%A2%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F-1"><span class="toc-number">0.1.</span> <span class="toc-text">1）子查询分页方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89join-%E5%88%86%E9%A1%B5%E6%96%B9%E5%BC%8F-1"><span class="toc-number">0.2.</span> <span class="toc-text">2）join 分页方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF-%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%EF%BC%88Cover-Index%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">基础知识：什么是  索引覆盖（Cover Index）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%95%E8%A1%A8%E5%9C%BA%E6%99%AF-limit-%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5-%E6%80%BB%E7%BB%93"><span class="toc-number"></span> <span class="toc-text">单表场景 limit 深度分页 总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E8%A1%A8%E5%9C%BA%E6%99%AF%EF%BC%8Climit%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5%E5%AD%98%E5%9C%A8%E7%9A%84%E4%B8%A5%E9%87%8D%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98"><span class="toc-number"></span> <span class="toc-text">分表场景，limit深度分页存在的严重性能问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E8%A1%A8%E5%9C%BA%E6%99%AF%E4%B8%8B-%E5%8A%9F%E8%83%BD%E5%92%8C%E6%80%A7%E8%83%BD%E7%9A%84%E5%86%B2%E7%AA%81%EF%BC%9A%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88-1"><span class="toc-number">0.1.</span> <span class="toc-text">分表场景下 功能和性能的冲突：从0开始的性能瓶颈</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sharding-JDBC%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8E%AA%E6%96%BD"><span class="toc-number">1.</span> <span class="toc-text">Sharding-JDBC的性能优化措施</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93%E7%84%B6%EF%BC%8C%E6%B5%81%E5%BC%8F%E6%9F%A5%E8%AF%A2%E7%9A%84%E4%B9%9F%E6%98%AF%E6%9C%89%E5%BC%8A%E7%AB%AF%E7%9A%84"><span class="toc-number">2.</span> <span class="toc-text">当然，流式查询的也是有弊端的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E8%A1%A8%E5%9C%BA%E6%99%AF-%E5%A4%A7%E8%A1%A8%E5%9C%BA%E6%99%AF%EF%BC%8Climit%E4%B8%A5%E9%87%8D%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">分表场景+大表场景，limit严重性能问题 如何解决？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%881%EF%BC%9A-%E7%A6%81%E6%AD%A2%E8%B7%B3%E9%A1%B5%E6%9F%A5%E8%AF%A2%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">优化方案1： 禁止跳页查询法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%952%EF%BC%9A%E4%BA%8C%E6%AC%A1%E6%9F%A5%E8%AF%A2%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">优化方法2：二次查询法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E6%AC%A1%E6%9F%A5%E8%AF%A2%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90-1"><span class="toc-number">5.1.</span> <span class="toc-text">二次查询法的一个例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%883%EF%BC%9A%E4%BD%BF%E7%94%A8-ES-HBASE-%E6%B5%B7%E9%87%8FNOSQL%E6%9E%B6%E6%9E%84%E6%96%B9%E6%A1%88"><span class="toc-number">6.</span> <span class="toc-text">优化方案3：使用 ES+HBASE 海量NOSQL架构方案</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/03/11/CAP%E5%AE%9A%E7%90%86-%E5%93%AA%E4%BA%9B%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AFAP-%E5%93%AA%E4%BA%9B%E6%98%AFCP-%E4%B8%BA%E4%BB%80%E4%B9%88/" title="CAP定理,哪些中间件是AP,哪些是CP,为什么"><img src="/img/liushui.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CAP定理,哪些中间件是AP,哪些是CP,为什么"/></a><div class="content"><a class="title" href="/2025/03/11/CAP%E5%AE%9A%E7%90%86-%E5%93%AA%E4%BA%9B%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AFAP-%E5%93%AA%E4%BA%9B%E6%98%AFCP-%E4%B8%BA%E4%BB%80%E4%B9%88/" title="CAP定理,哪些中间件是AP,哪些是CP,为什么">CAP定理,哪些中间件是AP,哪些是CP,为什么</a><time datetime="2025-03-11T01:05:25.000Z" title="发表于 2025-03-11 09:05:25">2025-03-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/08/elk%E5%9C%A3%E7%BB%8F%EF%BC%9AElasticsearch%E3%80%81Logstash%E3%80%81Kibana%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/" title="elk圣经：Elasticsearch、Logstash、Kibana从入门到精通"><img src="/img/liushui.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="elk圣经：Elasticsearch、Logstash、Kibana从入门到精通"/></a><div class="content"><a class="title" href="/2025/03/08/elk%E5%9C%A3%E7%BB%8F%EF%BC%9AElasticsearch%E3%80%81Logstash%E3%80%81Kibana%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/" title="elk圣经：Elasticsearch、Logstash、Kibana从入门到精通">elk圣经：Elasticsearch、Logstash、Kibana从入门到精通</a><time datetime="2025-03-08T07:49:00.000Z" title="发表于 2025-03-08 15:49:00">2025-03-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/06/%E4%BA%BF%E7%BA%A7redis%E6%8E%92%E8%A1%8C%E6%A6%9C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1/" title="亿级redis排行榜如何设计"><img src="/img/liushui.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="亿级redis排行榜如何设计"/></a><div class="content"><a class="title" href="/2025/03/06/%E4%BA%BF%E7%BA%A7redis%E6%8E%92%E8%A1%8C%E6%A6%9C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1/" title="亿级redis排行榜如何设计">亿级redis排行榜如何设计</a><time datetime="2025-03-06T13:16:31.000Z" title="发表于 2025-03-06 21:16:31">2025-03-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/05/1000%E4%B8%87%E7%BA%A7%E5%A4%A7%E8%A1%A8-%E5%A6%82%E4%BD%95-%E5%8A%A0%E7%B4%A2%E5%BC%95/" title="1000万级大表, 如何加索引"><img src="/img/liushui.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="1000万级大表, 如何加索引"/></a><div class="content"><a class="title" href="/2025/03/05/1000%E4%B8%87%E7%BA%A7%E5%A4%A7%E8%A1%A8-%E5%A6%82%E4%BD%95-%E5%8A%A0%E7%B4%A2%E5%BC%95/" title="1000万级大表, 如何加索引">1000万级大表, 如何加索引</a><time datetime="2025-03-05T03:31:17.000Z" title="发表于 2025-03-05 11:31:17">2025-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/05/%E4%BA%BF%E7%BA%A7%E7%94%A8%E6%88%B7%E6%97%A5%E6%B4%BB%E6%9C%88%E6%B4%BB%EF%BC%8C%E5%A6%82%E4%BD%95%E7%BB%9F%E8%AE%A1/" title="亿级用户日活月活，如何统计"><img src="/img/liushui.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="亿级用户日活月活，如何统计"/></a><div class="content"><a class="title" href="/2025/03/05/%E4%BA%BF%E7%BA%A7%E7%94%A8%E6%88%B7%E6%97%A5%E6%B4%BB%E6%9C%88%E6%B4%BB%EF%BC%8C%E5%A6%82%E4%BD%95%E7%BB%9F%E8%AE%A1/" title="亿级用户日活月活，如何统计">亿级用户日活月活，如何统计</a><time datetime="2025-03-05T02:50:21.000Z" title="发表于 2025-03-05 10:50:21">2025-03-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By 周五打工人</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://mywaline-7unwzwfdi-motors-projects-a4d09e71.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://mywaline-7unwzwfdi-motors-projects-a4d09e71.vercel.app/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.31/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>